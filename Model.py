import os
import json
import random
from typing import Callable, Dict, List, Optional, Tuple
import torch
import numpy as np
import DeepSDFStruct.deep_sdf.data as deep_data
import DeepSDFStruct.deep_sdf.training as training
from VisualizeAShape import visualize_a_shape
import multiprocessing
import warnings
import math
from DeepSDFStruct.deep_sdf.networks.deep_sdf_decoder import DeepSDFDecoder as Decoder

# ------------------------
# Limit CPU threads globally
# unique to the  machine. 
# Additionally deepSDFStruct and the original deepSDF support NVDIA GPU acceleration
# this has not been implemented in the script but would be useful
# ------------------------
NUM_CORES = multiprocessing.cpu_count()

# Set environment variables for parallel libraries
os.environ["OMP_NUM_THREADS"] = str(NUM_CORES)
os.environ["MKL_NUM_THREADS"] = str(NUM_CORES)

# Configure PyTorch threading
torch.set_num_threads(NUM_CORES)
torch.set_num_interop_threads(min(4, NUM_CORES // 2))

print(f"Configured PyTorch to use {NUM_CORES} CPU cores.")

# ------------------------
# Patch DeepSDF loader for flat SdfSamples
# ------------------------
def patch_get_instance_filenames():
    def get_instance_filenames(data_source, split):
        npyfiles = []
        for split_name, classes in split.items():
            for class_name, instances in classes.items():
                for instance_name in instances:
                    npyfiles.append(f"{instance_name}.npz")
        return npyfiles
    deep_data.get_instance_filenames = get_instance_filenames

patch_get_instance_filenames()

# ------------------------
# Caution! 
# Upon resuming training this script generates log.pth files to satisfy DeepSDF's API. 
#
# the log.pth generated by the script are dummy files and do not contain any logs
#
# Any such useful informtion could be extracted from this script with
# minor modifications however. 
# ------------------------
SDFCallable = Callable[[torch.Tensor, torch.Tensor | None], torch.Tensor]
SceneWithOperators = Dict[int, Tuple[SDFCallable, List[Tuple[float, float]]]]
Scenes = Dict[str, SceneWithOperators]

class Model: 
    def __init__(
        self,
        base_directory: str,
        model_name: str,
        scenes: Scenes,
        resume: bool = True,
        domainRadius: float = 1.0,
        latentDim: int = 1,
        FORCE_ONLY_FINAL_SNAPSHOT: bool = False,
        NumEpochs: int =500,
        ScenesPerBatch: int = 0,
    ):
        self.base_directory = base_directory
        self.model_name = model_name
        self.scenes = scenes
        self.resume = resume
        self.domainRadius = domainRadius
        self.latentDim = latentDim
        self.FORCE_ONLY_FINAL_SNAPSHOT = FORCE_ONLY_FINAL_SNAPSHOT
        self.trained_scenes: Dict[str,Scene] = {}
        self.NumEpochs = NumEpochs
        if ScenesPerBatch >0:
            self.ScenesPerBatch = ScenesPerBatch
        else:
            self.ScenesPerBatch = len(scenes)

    def trainModel(self
    ):
        """
        Train a DeepSDF model on SDFs with compatibility to interpolate between SDFs.
        Operator codes are provided optionally as an attempt to encode multiple functions in a scene.
        Scenes and operators for a scene are wrapped to contain additional input parameters beyond xyz.
        The only condition for compatibility is that all scenes and operators must have the same number of additional parameters.
        Additionally the model should only be trained on watertight smooth shapes for best results.
        If only one opertor is provided per scene the operator code input is omitted.

        """

        # ------------- derive global param space from scenes -------------
        global_add_param_ranges = []
        global_add_num_params = []

        for scene_name, scene in self.scenes.items():
            scene_param_ranges = []
            for op_params in scene.values():
                if isinstance(op_params, (list, tuple)):
                    for rng in op_params:
                        if isinstance(rng, (list, tuple)) and len(rng) == 2:
                            lo, hi = rng
                            if hi >= lo:
                                scene_param_ranges.append((lo, hi))
                            else: 
                                scene_param_ranges.append ((hi,lo))
            
            scene_add_n_params = len(scene_param_ranges)/len(scene.values())
            if scene_add_n_params != int(scene_add_n_params):
                raise ValueError("Inconsistent number of parameters across operators in scene" + scene_name)
            
            if len(scene.values()) >1: scene_add_n_params +=1 

            for i in range(0,len(scene_param_ranges)-1):
                if (scene_param_ranges[i] != scene_param_ranges[i+1]):
                    warnings.warn(f"Inconsistent range of parameters between operators : {i} and {i+1} probably not the best for training")
                
            global_add_param_ranges.append(scene_param_ranges)
            global_add_num_params.append(int(scene_add_n_params))

        for i in range(0,len(global_add_param_ranges)-1):
            if (global_add_param_ranges[i].__len__() != global_add_param_ranges[i+1].__len__()):
                raise ValueError(f"Inconsistent number of parameters between scenes : {list(self.scenes.keys())[i]} and {list(self.scenes.keys())[i+1]} probably not the best for training")
            
            if (global_add_param_ranges[i] != global_add_param_ranges[i+1]):
                warnings.warn(f"Inconsistent range of parameters between scenes :  {list(self.scenes.keys())[i]} and {list(self.scenes.keys())[i+1]} probably not the best for training")
        
        geom_n_params = global_add_num_params[0] +3 # all scenes must have same number of params

        # Define subdirectories consistently
        split_dir = os.path.join(self.base_directory, "split")
        model_params_dir = os.path.join(self.base_directory, "ModelParameters")
        
        samples_dir = os.path.join(self.base_directory, "SdfSamples")
        top_latent_dir = os.path.join(self.base_directory, "LatentCodes")
        optimizer_params_dir = os.path.join(self.base_directory, "OptimizerParameters")

        # Create them if needed
        for d in [self.base_directory, split_dir, model_params_dir, samples_dir, top_latent_dir]:
            os.makedirs(d, exist_ok=True)
    
        print(f"[DEBUG] Using experiment directory: {self.base_directory}")
        print(f"[DEBUG] Latent code directory: {top_latent_dir}")

        # ---------------- Load latest top-level latent codes for resume ----------------
        existing_ckpts = [
            f for f in os.listdir(top_latent_dir) if f.endswith(".pth") and f[:-4].isdigit()
        ]
        latest_epoch = max([int(f[:-4]) for f in existing_ckpts], default=0)

        top_data = {"latent_codes": {}}
        if existing_ckpts:
            top_ckpt_file = os.path.join(top_latent_dir, f"{latest_epoch}.pth")
            top_data = torch.load(top_ckpt_file, map_location="cpu")
            print(f"[DEBUG] Loaded top-level latent codes from {top_ckpt_file}, epoch {latest_epoch}")
        else:
            print(f"[DEBUG] No top-level latent codes found, starting fresh.")

        # ---------------- Specs ----------------
        specs_path = os.path.join(self.base_directory, "specs.json")
        if os.path.exists(specs_path):
            with open(specs_path) as f:
                specs = json.load(f)
        else:
            specs = {
                "Description": f"Train DeepSDF on analytic {self.model_name} shapes.",
                "NetworkArch": "deep_sdf_decoder",
                "DataSource": self.base_directory,
                "TrainSplit": os.path.join(self.base_directory, "split", "TrainSplit.json"),
                "NetworkSpecs": {
                    "dims": [128]*6,
                    "dropout": list(range(6)),
                    "dropout_prob": 0.2,
                    "norm_layers": list(range(6)),
                    "latent_in": [2] if self.latentDim > 0 else [],
                    "xyz_in_all": False,
                    "use_tanh": False,
                    "latent_dropout": False,
                    "weight_norm": True,
                    "geom_dimension": geom_n_params
                },
                "CodeLength": self.latentDim,
                "NumEpochs": self.NumEpochs,
                "SnapshotFrequency": 1,
                "AdditionalSnapshots": [1, 5],
                "LearningRateSchedule": [
                    {"Type": "Step", "Initial": 0.0005, "Interval": 250, "Factor": 0.5},
                    {
                    "Type" : "Step",
                    "Initial" : 0.001,
                    "Interval" : 250,
                    "Factor" : 0.5
                    }
                ],
                "SamplesPerScene": 50000,
                "ScenesPerBatch": self.ScenesPerBatch,
                "DataLoaderThreads": 1,
                "ClampingDistance": 0.1,
                "CodeRegularization": True,
                "CodeRegularizationLambda": 1e-4,
                "CodeBound": 1.0
            }

        if self.FORCE_ONLY_FINAL_SNAPSHOT:
            specs["SnapshotFrequency"] = specs["NumEpochs"]
            specs["AdditionalSnapshots"] = [specs["NumEpochs"]]

        with open(specs_path, "w") as f:
            json.dump(specs, f, indent=2)

        # ---------------- TrainSplit.json ----------------
        train_split_path = os.path.join(split_dir, "TrainSplit.json")
        if os.path.exists(train_split_path):
            with open(train_split_path) as f:
                split_dict = json.load(f)
        else:
            split_dict = {"train": {}}
        split_dict.setdefault("train", {}).setdefault(self.model_name, [])
        for scene_id in self.scenes.keys():
            #key = f"{self.model_name.lower()}_{scene_id:03d}"

            key = f"{self.model_name.lower()}_{scene_id}"

            if key not in split_dict["train"][self.model_name]:
                split_dict["train"][self.model_name].append(key)
        with open(train_split_path, "w") as f:
            json.dump(split_dict, f, indent=2)

        # ================================================================
        # Begin scene sampling loop (deterministic, angular-uniform, textbook DeepSDF)
        # ================================================================
        for scene_idx, (scene_id, scene_with_operators) in enumerate(self.scenes.items()):
            instance_key = f"{self.model_name.lower()}_{scene_id}"
            samples_file = os.path.join(samples_dir, f"{instance_key}.npz")

            print("\n" + "=" * 62)
            print(f"[SAMPLE] Begin sampling for scene: {instance_key}")
            print("=" * 62)

            if os.path.exists(samples_file):
                print(f"[SAMPLE] Existing file found, skipping: {samples_file}")
                continue

            operator_keys = list(scene_with_operators.keys())
            random.shuffle(operator_keys)
            n_ops = len(operator_keys)

            param_ranges_flat = global_add_param_ranges[scene_idx]
            cl = float(specs.get("ClampingDistance", 0.1))

            print(f"[SCENE] Operators: {operator_keys}")
            print(f"[SCENE] Param ranges (flat): {param_ranges_flat}")
            print(f"[SCENE] Clamping distance: {cl}")

            # angular grid
            NUM_AZ, NUM_EL = 36, 18
            NUM_BINS = NUM_AZ * NUM_EL

            # -------------------------------
            # Helpers
            # -------------------------------
            def estimate_center(sdf_fn, fallback=torch.zeros(3, dtype=torch.float32), probe_N=100000):
                probe_pts = (torch.rand(probe_N, 3) * 2 - 1) * self.domainRadius
                sdf_vals = sdf_fn(probe_pts, None)
                if sdf_vals.dim() == 2:
                    sdf_vals = sdf_vals[:, 0]
                mask = torch.abs(sdf_vals) < max(0.3, cl * 3)
                if mask.sum() < 128:
                    print("[WARN] Center estimate: not enough near-surface points, fallback to origin")
                    return fallback

                near_pts = probe_pts[mask]
                near_sdf = sdf_vals[mask]

                projected = near_pts - near_sdf.unsqueeze(1) * (
                    near_pts / (near_pts.norm(dim=1, keepdim=True) + 1e-12)
                )
                center_est = projected.median(dim=0).values

                # refinement
                local_N = min(20000, probe_N)
                local_pts = center_est + (torch.rand(local_N, 3) * 2 - 1) * self.domainRadius * 0.1
                local_sdf = sdf_fn(local_pts, None)
                if local_sdf.dim() == 2:
                    local_sdf = local_sdf[:, 0]

                mask2 = torch.abs(local_sdf) < max(0.3, cl * 3)
                if mask2.sum() > 64:
                    projected2 = local_pts[mask2] - local_sdf[mask2].unsqueeze(1) * (
                        local_pts[mask2] / (local_pts[mask2].norm(dim=1, keepdim=True) + 1e-12)
                    )
                    center_est = projected2.median(dim=0).values

                return center_est

            def sample_uniform_dirs(n):
                v = torch.randn(n, 3)
                return v / (v.norm(dim=1, keepdim=True) + 1e-12)

            def dirs_grid_tensor(num_az=NUM_AZ, num_el=NUM_EL):
                az = torch.linspace(0.0, 2.0 * np.pi, num_az + 1)[:-1]
                el = torch.linspace(-0.5 * np.pi, 0.5 * np.pi, num_el)
                az_g, el_g = torch.meshgrid(az, el, indexing="ij")
                dirs = torch.stack([
                    torch.cos(el_g) * torch.cos(az_g),
                    torch.cos(el_g) * torch.sin(az_g),
                    torch.sin(el_g)
                ], dim=-1)
                return dirs.reshape(-1, 3)

            def estimate_surface_radius(sdf_fn, center, num_probes=2048):
                dirs = sample_uniform_dirs(num_probes)
                probes = center.unsqueeze(0) + dirs * (self.domainRadius * 0.95)
                sd = sdf_fn(probes, None)
                if sd.dim() == 2:
                    sd = sd[:, 0]
                approx = ((probes - center.unsqueeze(0)).norm(dim=1) - sd).cpu().numpy()
                r = float(np.median(approx))
                return r if np.isfinite(r) and r > 0 else float(self.domainRadius * 0.9)

            # -------------------------------------------------------------
            # Estimate center
            # -------------------------------------------------------------
            any_sdf_fn, _ = next(iter(scene_with_operators.values()))
            shape_center = estimate_center(any_sdf_fn).float()
            print(f"[INFO] Estimated center: {shape_center.tolist()}")

            # -------------------------------------------------------------
            # Per-operator sampling budgets
            # -------------------------------------------------------------
            total_target = int(specs["SamplesPerScene"] // max(1, n_ops))
            target_pos = total_target // 2
            target_neg = total_target - target_pos

            print(f"[SCENE] Total target per operator: {total_target}")
            print(f"[SCENE] Target pos={target_pos}, neg={target_neg}")

            pos_chunks, neg_chunks = [], []
            directions = dirs_grid_tensor()

            # =============================================================
            # Per-operator sampling
            # =============================================================
            for op_idx, key in enumerate(operator_keys):
                sdf_fn, _ = scene_with_operators[key]

                # parameter ranges
                if len(param_ranges_flat) > op_idx and len(param_ranges_flat[op_idx]) > 0:
                    pr = param_ranges_flat[op_idx]
                    low = torch.tensor([a for a, _ in pr], dtype=torch.float32)
                    high = torch.tensor([b for _, b in pr], dtype=torch.float32)
                    n_params = len(pr)
                else:
                    pr = None
                    low = high = None
                    n_params = 0

                print(f"\n[OP {key}] ------------------------------")
                print(f"[OP {key}] Param count: {n_params}")
                print(f"[OP {key}] Param ranges: {pr}")

                # radius
                R = estimate_surface_radius(sdf_fn, shape_center)
                shell_min = max(0.0, R - cl * 1.5)
                shell_max = R + cl * 1.5

                print(f"[OP {key}] Radius R={R:.5f}")
                print(f"[OP {key}] Shell range = [{shell_min:.5f}, {shell_max:.5f}]")

                op_pos = []
                op_neg = []

                # for spherical uniformity logging
                bin_hits = np.zeros(NUM_BINS, dtype=np.int32)

                sweeps = 0
                max_sweeps = 10
                total_narrowband = 0
                total_tested = 0
                # ----------------------------------------------------------
                # Directional sweeps
                # ----------------------------------------------------------
                while (len(op_pos) < target_pos or len(op_neg) < target_neg) and sweeps < max_sweeps:
                    sweeps += 1
                    for bin_idx, d in enumerate(directions):
                        if len(op_pos) >= target_pos and len(op_neg) >= target_neg:
                            break

                        r = shell_min + torch.rand(1).item() * (shell_max - shell_min)
                        xyz = (shape_center + d * r).unsqueeze(0)

                        if n_params > 0:
                            rp = torch.rand(1, n_params)
                            params = (low + rp * (high - low)).float()
                        else:
                            params = None

                        sdf_val = sdf_fn(xyz, params)
                        if sdf_val.dim() == 2:
                            sdf_val = sdf_val[:, 0]
                        v = float(sdf_val.item())

                        if abs(v) > cl:
                            continue

                        # spherical bin hit
                        bin_hits[bin_idx] += 1

                        # ---sweep narrowband accounting ---
                        total_tested += 1
                        total_narrowband += 1


                        xyz_np = xyz[0].cpu().numpy().astype(np.float32)
                        if params is not None:
                            params_np = params[0].cpu().numpy().astype(np.float32)
                            row = np.concatenate([xyz_np, params_np, np.array([v], dtype=np.float32)])
                        else:
                            row = np.concatenate([xyz_np, np.array([v], dtype=np.float32)])

                        if v >= 0.0 and len(op_pos) < target_pos:
                            op_pos.append(row)
                        elif v < 0.0 and len(op_neg) < target_neg:
                            op_neg.append(row)

                print(f"[OP {key}] Sweeps: {sweeps}/{max_sweeps}")
                print(f"[OP {key}] After sweeps: pos={len(op_pos)}, neg={len(op_neg)}")

                # ----------------------------------------------------------
                # Volume fill attempts
                # ----------------------------------------------------------
                fill_attempts = 0
                max_fill_attempts = 5000



                while (len(op_pos) < target_pos or len(op_neg) < target_neg) and fill_attempts < max_fill_attempts:
                    fill_attempts += 1

                    batch = 4096
                    pts = (torch.rand(batch, 3) * 2 - 1) * self.domainRadius + shape_center.unsqueeze(0)
                    dists = (pts - shape_center.unsqueeze(0)).norm(dim=1)
                    mask_sphere = dists <= self.domainRadius
                    if mask_sphere.sum() == 0:
                        continue
                    pts = pts[mask_sphere]

                    if n_params > 0:
                        rp = torch.rand(pts.shape[0], n_params)
                        params_batch = (low.unsqueeze(0) + rp * (high - low).unsqueeze(0)).float()
                    else:
                        params_batch = None

                    sdf_batch = sdf_fn(pts, params_batch)
                    if sdf_batch.dim() == 2:
                        sdf_batch = sdf_batch[:, 0]

                    sdf_np = sdf_batch.cpu().numpy().astype(np.float32)
                    pts_np = pts.cpu().numpy().astype(np.float32)

                    total_tested += pts_np.shape[0]
                    total_narrowband += np.sum(np.abs(sdf_np) <= cl)

                    for i in range(pts_np.shape[0]):
                        if len(op_pos) >= target_pos and len(op_neg) >= target_neg:
                            break
                        v = float(sdf_np[i])
                        if abs(v) > cl:
                            continue

                        xyz_np = pts_np[i]
                        # --- fill-time spherical bin update ---
                        v_dir = xyz_np - shape_center.cpu().numpy().astype(np.float32)
                        norm = np.linalg.norm(v_dir)
                        if norm > 1e-12:
                            x, y, z = v_dir / norm
                            el = np.arcsin(z)
                            az = np.arctan2(y, x) % (2*np.pi)
                            az_bin = int(az / (2*np.pi) * NUM_AZ)
                            el_bin = int((el + 0.5*np.pi) / (np.pi) * NUM_EL)
                            bin_idx2 = az_bin * NUM_EL + el_bin
                            if 0 <= bin_idx2 < NUM_BINS:
                                bin_hits[bin_idx2] += 1

                        if params_batch is not None:
                            params_np = params_batch[i].cpu().numpy().astype(np.float32)
                            row = np.concatenate([xyz_np, params_np, np.array([v], dtype=np.float32)])
                        else:
                            row = np.concatenate([xyz_np, np.array([v], dtype=np.float32)])

                        if v >= 0.0 and len(op_pos) < target_pos:
                            op_pos.append(row)
                        elif v < 0.0 and len(op_neg) < target_neg:
                            op_neg.append(row)

                print(f"[OP {key}] Fill attempts: {fill_attempts}/{max_fill_attempts}")
                print(f"[OP {key}] After fill: pos={len(op_pos)}, neg={len(op_neg)}")
                # --- NEW: track pre-padding pos/neg ---
                true_pos = len(op_pos)
                true_neg = len(op_neg)

                # ----------------------------------------------------------
                # Padding if required
                # ----------------------------------------------------------
                if len(op_pos) < target_pos:
                    repeats = target_pos - len(op_pos)
                    print(f"[WARN][OP {key}] Padding positive: {repeats}")
                    op_pos.extend([op_pos[-1].copy() for _ in range(repeats)])
                if len(op_neg) < target_neg:
                    repeats = target_neg - len(op_neg)
                    print(f"[WARN][OP {key}] Padding negative: {repeats}")
                    op_neg.extend([op_neg[-1].copy() for _ in range(repeats)])

                op_pos_arr = np.vstack(op_pos).astype(np.float32)
                op_neg_arr = np.vstack(op_neg).astype(np.float32)

                print(f"[OP {key}] Final operator distribution: pos={op_pos_arr.shape[0]}, "
                    f"neg={op_neg_arr.shape[0]}, cols={op_pos_arr.shape[1]}")

                # ============================================================
                # === SPHERICAL UNIFORMITY ======================
                # ============================================================
                nonempty_bins = np.sum(bin_hits > 0)
                spherical_uniformity = nonempty_bins / float(NUM_BINS)
                print(f"[OP {key}] Spherical uniformity: {spherical_uniformity:.4f} "
                    f"({nonempty_bins}/{NUM_BINS} bins hit)")

                # ============================================================
                # === DeepSDF EFFECTIVENESS SCORE ===============
                # ============================================================
                posneg_balance = (min(true_pos, true_neg) / max(true_pos, true_neg)) if max(true_pos, true_neg) > 0 else 0.0

                narrowband_fraction = (total_narrowband / total_tested) if total_tested > 0 else 0.0

                effectiveness = (spherical_uniformity + posneg_balance + narrowband_fraction) / 3.0


                print(f"[OP {key}] DeepSDF effectiveness score: {effectiveness:.4f}")
                print(f"[OP {key}] Breakdown â†’ uniformity={spherical_uniformity:.4f}, "
                    f"balance={posneg_balance:.4f}, nb_fraction={narrowband_fraction:.4f}")

                pos_chunks.append(op_pos_arr)
                neg_chunks.append(op_neg_arr)

            # ============================================================
            # Merge + save
            # ============================================================
            pos = np.vstack(pos_chunks) if pos_chunks else np.empty((0, 4), dtype=np.float32)
            neg = np.vstack(neg_chunks) if neg_chunks else np.empty((0, 4), dtype=np.float32)

            if pos.shape[1] != neg.shape[1]:
                min_cols = min(pos.shape[1], neg.shape[1])
                print(f"[WARN] Column mismatch: pos={pos.shape[1]}, neg={neg.shape[1]}, trimming to {min_cols}")
                pos = pos[:, :min_cols]
                neg = neg[:, :min_cols]

            print(f"[SCENE {instance_key}] Final total pos={pos.shape[0]}")
            print(f"[SCENE {instance_key}] Final total neg={neg.shape[0]}")
            print(f"[SCENE {instance_key}] Columns per sample={pos.shape[1]}")

            print(f"[SAVE] Writing: {samples_file}")
            np.savez_compressed(samples_file, pos=pos.astype(np.float32), neg=neg.astype(np.float32))

            print("=" * 62)
            print(f"[SAMPLE] Completed scene: {instance_key}")
            print("=" * 62)
         

            # -------------------------------
            # Quick sanity check visualization
            # -------------------------------
            try:
                import matplotlib.pyplot as plt
                from mpl_toolkits.mplot3d import Axes3D
            except ImportError:
                print("[WARN] Matplotlib not installed, skipping visualization.")
                plt = None

            if plt is not None:
                # Use only points near the zero-level set
                narrowband = np.vstack([pos, neg])
                mask = np.abs(narrowband[:, -1]) < cl  # last column = SDF value
                surface_points = narrowband[mask, :3]

                print(f"[INFO] Visualizing {surface_points.shape[0]} surface points")

                if surface_points.shape[0] > 0:
                    fig = plt.figure(figsize=(6, 6))
                    ax = fig.add_subplot(111, projection='3d')
                    ax.scatter(surface_points[:, 0], surface_points[:, 1], surface_points[:, 2],
                            color='blue', s=1, alpha=0.6)
                    ax.set_title(f"Sanity Check: Surface points for {instance_key}")
                    ax.set_xlabel('X'); ax.set_ylabel('Y'); ax.set_zlabel('Z')
                    ax.set_box_aspect([1,1,1])
                    fig.savefig(os.path.join(samples_dir, f"{instance_key}_samples.png"), dpi=150)
                    plt.close(fig)
                    print(f"[INFO] Saved surface point visualization to {instance_key}_samples.png")

                else:
                    print("[WARN] No points in narrowband; nothing to plot.")

        # ================================================================
        # End scene sampling loop
        # ================================================================

        # ---------------- Training (Single Pass Over All Scenes) ----------------
        print(f"[INFO] Starting unified DeepSDF training for all {len(self.scenes)} scenes.")

        # Find if we have an existing checkpoint
        existing_model_ckpts = [
            f for f in os.listdir(model_params_dir) if f.endswith(".pth") and f[:-4].isdigit()
        ]
        existing_latent_ckpts = [
            f for f in os.listdir(top_latent_dir) if f.endswith(".pth") and f[:-4].isdigit()
        ]
        latest_epoch = max([int(f[:-4]) for f in existing_model_ckpts], default=0)
        resume_ckpt = str(latest_epoch) if existing_model_ckpts else None

        if resume_ckpt:
            print(f"[INFO] Resuming from epoch {latest_epoch}")
        else:
            print("[INFO] Starting training from scratch")

        # Initialize latent codes if not found
        if not existing_latent_ckpts:
            sigma = 1.0 / math.sqrt(self.latentDim)
            init_latents = torch.normal(0.0, sigma, size=(len(self.scenes), self.latentDim))
            init_latent_dict = {
                "latent_codes": {"weight": init_latents},
                "epoch": 0
            }
            torch.save(init_latent_dict, os.path.join(top_latent_dir, "0.pth"))
            print(f"[INFO] Initialized new latent code matrix for {len(self.scenes)} scenes.")

        # Create dummy logs if needed (DeepSDF expects it)
        logs_file = os.path.join(self.base_directory, "Logs.pth")
        if not os.path.exists(logs_file):
            torch.save({
                "loss": [0.0],
                "learning_rate": [0.001],
                "timing": [0.0],
                "latent_magnitude": [0.0],
                "param_magnitude": {"dummy": [0.0]},
                "epoch": [latest_epoch],
            }, logs_file)

        # Run DeepSDF once for all scenes
        old_cwd = os.getcwd()
        os.chdir(self.base_directory)
        try:
            training.train_deep_sdf(
                experiment_directory=self.base_directory,
                data_source=self.base_directory,
                continue_from=resume_ckpt,
                batch_split=1
            )
        finally:
            os.chdir(old_cwd)

        # ---------------- Load final trained latents ----------------
        post_ckpts = [
            f for f in os.listdir(top_latent_dir) if f.endswith(".pth") and f[:-4].isdigit()
        ]
        if not post_ckpts:
            raise RuntimeError(f"No latent checkpoints found in {top_latent_dir}")
        final_epoch = max(int(f[:-4]) for f in post_ckpts)
        top_latent_path = os.path.join(top_latent_dir, f"{final_epoch}.pth")

        latent_data = torch.load(top_latent_path, map_location="cpu")
        latent_weight = latent_data["latent_codes"]["weight"]

        print(f"[INFO] Loaded final latent codes from epoch {final_epoch}: shape = {latent_weight.shape}")

        # ---------------- Register trained scenes ----------------
        for idx, scene_id in enumerate(self.scenes.keys()):
            scene_key = f"{self.model_name.lower()}_{scene_id}"
            latent_vec = latent_weight[idx]
            self.trained_scenes[scene_key] = Scene(
                parent_model=self,
                scene_key=scene_key,
                latent_vector=latent_vec
            )
        print(f"[INFO] Registered {len(self.trained_scenes)} trained scenes.")


    def get_scene(self, scene_key: str) -> "Scene":
        """Return a Scene instance by key."""
        return self.trained_scenes[scene_key]
    
    def compute_sdf_from_latent(
        self,
        latent_vector: torch.Tensor,
        xyz: torch.Tensor,
        params: Optional[torch.Tensor] = None,
        chunk: int = 50000,
    ):
        """
        Evaluate the trained DeepSDF decoder at xyz locations for a given latent vector.
        Matches the behavior of visualize_a_shape.
        """

        root = self.base_directory
        specs_file = os.path.join(root, "specs.json")

        with open(specs_file, "r") as f:
            specs = json.load(f)

        geom_dim = specs["NetworkSpecs"].get("geom_dimension", 3)

        # ---------------- Load decoder checkpoint ----------------
        model_params_dir = os.path.join(root, "ModelParameters")
        ckpts = [f for f in os.listdir(model_params_dir) if f.endswith(".pth") and f[:-4].isdigit()]
        if not ckpts:
            raise FileNotFoundError(f"No decoder checkpoints found in {model_params_dir}")

        latest_epoch = max(int(f[:-4]) for f in ckpts)
        decoder_path = os.path.join(model_params_dir, f"{latest_epoch}.pth")

        # ---------------- Construct decoder ----------------
        decoder = Decoder(
            latent_size=specs["CodeLength"],
            dims=specs["NetworkSpecs"]["dims"],
            geom_dimension=geom_dim,
            norm_layers=tuple(specs["NetworkSpecs"].get("norm_layers", ())),
            latent_in=tuple(specs["NetworkSpecs"].get("latent_in", ())),
            weight_norm=specs["NetworkSpecs"].get("weight_norm", False),
            xyz_in_all=specs["NetworkSpecs"].get("xyz_in_all", False),
            use_tanh=specs["NetworkSpecs"].get("use_tanh", False),
        )

        ckpt = torch.load(decoder_path, map_location=xyz.device)
        decoder.load_state_dict(ckpt["model_state_dict"])
        decoder.to(xyz.device).eval()

        # ---------------- Sanitize latent ----------------
        if latent_vector.dim() == 1:
            latent_vector = latent_vector.unsqueeze(0)
        latent_vector = latent_vector.to(xyz.device).float().contiguous()

        # ---------------- Sanitize params ----------------
        if params is not None:
            if params.dim() == 1:
                params = params.unsqueeze(0)
            params = params.float().to(xyz.device).contiguous()

        # ---------------- Chunked SDF evaluation ----------------
        outputs = []
        with torch.no_grad():
            N = xyz.shape[0]
            for i in range(0, N, chunk):
                pts = xyz[i:i + chunk]

                if params is not None:
                    pts = torch.cat([pts, params.expand(pts.size(0), -1)], dim=1)

                latent_repeat = latent_vector.expand(pts.size(0), -1)
                decoder_input = torch.cat([latent_repeat, pts], dim=1)

                sdf_chunk = decoder(decoder_input)
                if sdf_chunk.dim() == 2:
                    sdf_chunk = sdf_chunk[:, 0]
                outputs.append(sdf_chunk)

        return torch.cat(outputs, dim=0)

    
class Scene():
    def __init__(self, parent_model: Model, scene_key: str, latent_vector: torch.Tensor):
        # Call the parent constructor to inherit model attributes
        self.parent_model = parent_model
        self.scene_key = scene_key
        self.latent_vector = latent_vector
        # Derive the raw scene id (everything after first underscore)
        raw_id = "_".join(scene_key.split("_")[1:])

        # Pull the operator dict from the parent model
        self.sdf_ops = self.parent_model.scenes.get(raw_id)
        if self.sdf_ops is None:
            raise KeyError(f"Scene id '{raw_id}' not found in parent model.scenes")

    def compute_sdf(self, xyz: torch.Tensor, params: torch.Tensor | None = None, operator: int = 0) -> torch.Tensor:
        """Compute SDF values for this scene using a given operator and optional parameters."""
            
        if self.sdf_ops is None:
            raise ValueError(f"No SDF operators defined for scene '{self.scene_key}'")

        # Lookup operator
        op_entry = self.sdf_ops.get(operator)
        if op_entry is None:
            raise KeyError(f"Operator index {operator} not found in scene '{self.scene_key}'")

        sdf_fn, _ = op_entry  # unpack (function, param_ranges)

        # Call the function with xyz and params
        try:
            sdf_vals = sdf_fn(xyz, params)
        except Exception as e:
            raise RuntimeError(f"Error evaluating SDF for scene '{self.scene_key}', operator {operator}: {e}")

        # Make sure output is the right shape
        if sdf_vals.dim() == 1:
            sdf_vals = sdf_vals.unsqueeze(1)

        return sdf_vals
            

    def compute_trained_sdf(
        self,
        xyz: torch.Tensor,
        params: Optional[torch.Tensor] = None,
        chunk: int = 50000,
    ):
        """
        Evaluate the trained DeepSDF decoder at xyz locations for this scene's latent vector.
        Matches the behavior of visualize_a_shape.
        """

        return self.parent_model.compute_sdf_from_latent(
            latent_vector=self.latent_vector,
            xyz=xyz,
            params=params,
            chunk=chunk,
        )
    
    def get_latent_vector(self) -> torch.Tensor:
        """Return the latent vector for this scene."""
        return self.latent_vector
        
    def visualize(
        self,
        grid_res: int = 128,
        clamp_dist: float = 0.1,
        param_values: list | None = None,
        save_suffix: str | None = None,
        experiment_root: str | None = None,
        ):
        """
        Visualize this scene using the trained latent vector.

        Args:
            grid_res (int): Grid resolution.
            clamp_dist (float): Clamp distance for SDF values.
            param_values (list of list, optional): Parameter vectors to visualize.
            save_suffix (str, optional): Suffix for saved mesh files.
            experiment_root (str, optional): Root directory for experiments.

        Returns:
            List[trimesh.Trimesh]: Generated meshes.
        """
        # Extract scene_id from the scene_key assuming format: "modelname_###"
        scene_id_str = self.scene_key.split("_")[-1]
        scene_id = int(scene_id_str)

        return visualize_a_shape(
            model_name=self.parent_model.model_name,
            scene_id=scene_id,
            grid_res=grid_res,
            clamp_dist=clamp_dist,
            param_values=param_values,
            latent=self.latent_vector,
            save_suffix=save_suffix,
            experiment_root=experiment_root,
        )