import os
import json
import random
from typing import Callable, Dict, List, Tuple
import torch
import numpy as np
import DeepSDFStruct.deep_sdf.data as deep_data
import DeepSDFStruct.deep_sdf.training as training

from VisualizeAShape import visualize_a_shape
import multiprocessing
import warnings
import math
import shutil

# ------------------------
# Limit CPU threads globally
# unique to the  machine. 
# Additionally deepSDFStruct and the original deepSDF support NVDIA GPU acceleration
# this has not been implemented in the script but would be useful
# ------------------------
NUM_CORES = multiprocessing.cpu_count()

# Set environment variables for parallel libraries
os.environ["OMP_NUM_THREADS"] = str(NUM_CORES)
os.environ["MKL_NUM_THREADS"] = str(NUM_CORES)

# Configure PyTorch threading
torch.set_num_threads(NUM_CORES)
torch.set_num_interop_threads(min(4, NUM_CORES // 2))

print(f"Configured PyTorch to use {NUM_CORES} CPU cores.")


# ------------------------
# Patch DeepSDF loader for flat SdfSamples
# ------------------------
def patch_get_instance_filenames():
    def get_instance_filenames(data_source, split):
        npyfiles = []
        for split_name, classes in split.items():
            for class_name, instances in classes.items():
                for instance_name in instances:
                    npyfiles.append(f"{instance_name}.npz")
        return npyfiles
    deep_data.get_instance_filenames = get_instance_filenames

patch_get_instance_filenames()

def safe_clean_directory(directory):
    for f in os.listdir(directory):
        file_path = os.path.join(directory, f)
        try:
            if os.path.isfile(file_path):
                os.remove(file_path)
                print(f"[DEBUG] Deleted {file_path}")
            elif os.path.isdir(file_path):            
                shutil.rmtree(file_path)
                print(f"[DEBUG] Deleted folder {file_path}")
        except Exception as e:
            print(f"[WARN] Could not delete {file_path}: {e}")


# ------------------------
# Caution! 
# Upon resuming training this script generates log.pth files to satisfy DeepSDF's API. 
#
# the log.pth generated by the script are dummy files and do not contain any logs
#
# Any such useful informtion could be extracted from this script with
# minor modifications however. 
# ------------------------
SDFCallable = Callable[[torch.Tensor, torch.Tensor | None], torch.Tensor]
SceneWithOperators = Dict[int, Tuple[SDFCallable, List[Tuple[float, float]]]]
Scenes = Dict[str, SceneWithOperators]

class Model: 
    def __init__(
        self,
        base_directory: str,
        model_name: str,
        scenes: Scenes,
        resume: bool = True,
        domainRadius: float = 1.0,
        latentDim: int = 1,
        FORCE_ONLY_FINAL_SNAPSHOT: bool = False
    ):
        self.base_directory = base_directory
        self.model_name = model_name
        self.scenes = scenes
        self.resume = resume
        self.domainRadius = domainRadius
        self.latentDim = latentDim
        self.FORCE_ONLY_FINAL_SNAPSHOT = FORCE_ONLY_FINAL_SNAPSHOT
        self.trained_scenes: Dict[str,Scene] = {}

    from DeepSDFStruct.deep_sdf.networks.deep_sdf_decoder import DeepSDFDecoder

    

    def trainModel(self
    ):
        """
        Train a DeepSDF model on SDFs with compatibility to interpolate between SDFs.
        Interpolation is achieved via operator parameters. 
        Scenes and operators for a scene are wrapped to contain additional input parameters beyond xyz.
        The only condition for compatibility is that all scenes and operators must have the same number of additional parameters.
        Additionally the model should only be trained on watertight smooth shapes for best results.
        If only one opertor is provided per scene the operator code input is omitted.
        """

        # ------------- derive global param space from scenes -------------
        global_add_param_ranges = []
        global_add_num_params = []

        for scene_name, scene in self.scenes.items():
            scene_param_ranges = []
            for op_params in scene.values():
                if isinstance(op_params, (list, tuple)):
                    for rng in op_params:
                        if isinstance(rng, (list, tuple)) and len(rng) == 2:
                            lo, hi = rng
                            if hi >= lo:
                                scene_param_ranges.append((lo, hi))
                            else: 
                                scene_param_ranges.append ((hi,lo))
            
            scene_add_n_params = len(scene_param_ranges)/len(scene.values())
            if scene_add_n_params != int(scene_add_n_params):
                raise ValueError("Inconsistent number of parameters across operators in scene" + scene_name)
            
            if len(scene.values()) >1: scene_add_n_params +=1 

            for i in range(0,len(scene_param_ranges)-1):
                if (scene_param_ranges[i] != scene_param_ranges[i+1]):
                    warnings.warn(f"Inconsistent range of parameters between operators : {i} and {i+1} probably not the best for training")
                
            global_add_param_ranges.append(scene_param_ranges)
            global_add_num_params.append(int(scene_add_n_params))

        for i in range(0,len(global_add_param_ranges)-1):
            if (global_add_param_ranges[i].__len__() != global_add_param_ranges[i+1].__len__()):
                raise ValueError(f"Inconsistent number of parameters between scenes : {list(self.scenes.keys())[i]} and {list(self.scenes.keys())[i+1]} probably not the best for training")
            
            if (global_add_param_ranges[i] != global_add_param_ranges[i+1]):
                warnings.warn(f"Inconsistent range of parameters between scenes :  {list(self.scenes.keys())[i]} and {list(self.scenes.keys())[i+1]} probably not the best for training")
        
        geom_n_params = global_add_num_params[0] +3 # all scenes must have same number of params

        # Define subdirectories consistently
        split_dir = os.path.join(self.base_directory, "split")
        model_params_dir = os.path.join(self.base_directory, "ModelParameters")
        scenes_dir = os.path.join(self.base_directory, "Scenes")
        samples_dir = os.path.join(self.base_directory, "SdfSamples")
        top_latent_dir = os.path.join(self.base_directory, "LatentCodes")
        optimizer_params_dir = os.path.join(self.base_directory, "OptimizerParameters")

        # Create them if needed
        for d in [self.base_directory, split_dir, model_params_dir, scenes_dir, samples_dir, top_latent_dir]:
            os.makedirs(d, exist_ok=True)
    
        print(f"[DEBUG] Using experiment directory: {self.base_directory}")
        print(f"[DEBUG] Latent code directory: {top_latent_dir}")

        # ---------------- Load latest top-level latent codes for resume ----------------
        existing_ckpts = [
            f for f in os.listdir(top_latent_dir) if f.endswith(".pth") and f[:-4].isdigit()
        ]
        latest_epoch = max([int(f[:-4]) for f in existing_ckpts], default=0)

        top_data = {"latent_codes": {}}
        if existing_ckpts:
            top_ckpt_file = os.path.join(top_latent_dir, f"{latest_epoch}.pth")
            top_data = torch.load(top_ckpt_file, map_location="cpu")
            print(f"[DEBUG] Loaded top-level latent codes from {top_ckpt_file}, epoch {latest_epoch}")
        else:
            print(f"[DEBUG] No top-level latent codes found, starting fresh.")

        # ---------------- Specs ----------------
        specs_path = os.path.join(self.base_directory, "specs.json")
        if os.path.exists(specs_path):
            with open(specs_path) as f:
                specs = json.load(f)
        else:
            specs = {
                "Description": f"Train DeepSDF on analytic {self.model_name} shapes.",
                "NetworkArch": "deep_sdf_decoder",
                "DataSource": self.base_directory,
                "TrainSplit": os.path.join(self.base_directory, "split", "TrainSplit.json"),
                "NetworkSpecs": {
                    "dims": [128]*6,
                    "dropout": list(range(6)),
                    "dropout_prob": 0.2,
                    "norm_layers": list(range(6)),
                    "latent_in": [2] if self.latentDim > 0 else [],
                    "xyz_in_all": False,
                    "use_tanh": False,
                    "latent_dropout": False,
                    "weight_norm": True,
                    "geom_dimension": geom_n_params
                },
                "CodeLength": self.latentDim,
                "NumEpochs": 5,
                "SnapshotFrequency": 1,
                "AdditionalSnapshots": [1, 5],
                "LearningRateSchedule": [
                    {"Type": "Step", "Initial": 0.001, "Interval": 250, "Factor": 0.5},
                    {"Type": "Constant", "Value": 0.001}
                ],
                "SamplesPerScene": 5000,
                "ScenesPerBatch": 1,
                "DataLoaderThreads": 1,
                "ClampingDistance": 0.1,
                "CodeRegularization": True,
                "CodeRegularizationLambda": 1e-4,
                "CodeBound": 1.0
            }

        if self.FORCE_ONLY_FINAL_SNAPSHOT:
            specs["SnapshotFrequency"] = specs["NumEpochs"]
            specs["AdditionalSnapshots"] = [specs["NumEpochs"]]

        with open(specs_path, "w") as f:
            json.dump(specs, f, indent=2)

        # ---------------- TrainSplit.json ----------------
        train_split_path = os.path.join(split_dir, "TrainSplit.json")
        if os.path.exists(train_split_path):
            with open(train_split_path) as f:
                split_dict = json.load(f)
        else:
            split_dict = {"train": {}}
        split_dict.setdefault("train", {}).setdefault(self.model_name, [])
        for scene_id in self.scenes.keys():
            #key = f"{self.model_name.lower()}_{scene_id:03d}"

            key = f"{self.model_name.lower()}_{scene_id}"

            if key not in split_dict["train"][self.model_name]:
                split_dict["train"][self.model_name].append(key)
        with open(train_split_path, "w") as f:
            json.dump(split_dict, f, indent=2)

        for scene_idx, (scene_id, scene_with_operators) in enumerate(self.scenes.items()):
            scene_key = f"{self.model_name.lower()}_{scene_id}"

            # --- SDF Samples---
            samples_file = os.path.join(samples_dir, f"{scene_key}.npz")
            if not os.path.exists(samples_file):

                # ---------------- Operator setup ----------------
                operator_keys = list(scene_with_operators.keys())
                random.shuffle(operator_keys)  # shuffle operators
                n_ops = len(operator_keys)

                param_ranges_flat = global_add_param_ranges[scene_idx]
                add_n_params_not_operator = global_add_num_params[scene_idx] -1 if n_ops >1 else global_add_num_params[scene_idx]

                # ---------------- Adaptive sampling per operator ----------------
                # Attempts to sample 50/50 split of inside/outside points per operator

                target_pos = target_neg = specs["SamplesPerScene"] // n_ops// 2
                pos_list, neg_list = [], []

                batch_size = 5000  # sample in batches to avoid memory blow-up
                max_attempts = 100  # safety to avoid infinite loops

                for i, key in enumerate(operator_keys):
                    op_idx = list(scene_with_operators.keys()).index(key)  # find the index in param_ranges_flat

                    #if no parameter ranges for this operator → skip param sampling
                    if len(param_ranges_flat) == 0:
                        # sample xyz
                        xyz = (torch.rand(batch_size, 3, dtype=torch.float32) * 2 - 1) * self.domainRadius

                        # assemble query depending on single vs multi op
                        if len(operator_keys) > 1:
                            op_value = torch.full((batch_size, 1), float(i), dtype=torch.float32)
                            queries_op = torch.cat([xyz, op_value], dim=1)
                        else:
                            queries_op = xyz

                        # evaluate SDF
                        sdf_fn, _ = scene_with_operators[key]
                        sdf_op_vals = sdf_fn(xyz, None)
                        if sdf_op_vals.dim() == 1:
                            sdf_op_vals = sdf_op_vals.unsqueeze(1)

                        data = torch.cat([queries_op, sdf_op_vals], dim=1).numpy()
                        sdf_col_idx = data.shape[1] - 1
                        batch_pos = data[np.abs(data[:, sdf_col_idx]) < specs["ClampingDistance"]]
                        batch_neg = data[np.abs(data[:, sdf_col_idx]) >= specs["ClampingDistance"]]

                        if len(pos_list) < target_pos:
                            remaining = target_pos - len(pos_list)
                            pos_list.append(batch_pos[:remaining])
                        if len(neg_list) < target_neg:
                            remaining = target_neg - len(neg_list)
                            neg_list.append(batch_neg[:remaining])

                        continue  #skip the parameter sampling path completely

                    # ---------- normal param case ----------
                    low_vals = torch.tensor([lo for lo, _ in param_ranges_flat[op_idx]], dtype=torch.float32)
                    high_vals = torch.tensor([hi for _, hi in param_ranges_flat[op_idx]], dtype=torch.float32)

                    attempts = 0
                    while (len(pos_list) < target_pos or len(neg_list) < target_neg) and attempts < max_attempts:
                        attempts += 1

                        # sample xyz
                        xyz = (torch.rand(batch_size, 3, dtype=torch.float32) * 2 - 1) * self.domainRadius

                        # sample operator parameters
                        rand_params = torch.rand((batch_size, add_n_params_not_operator), dtype=torch.float32)
                        sampled_params = low_vals + rand_params * (high_vals - low_vals)

                        # continuous operator code (column 4)
                        op_value = torch.full((batch_size, 1), float(i), dtype=torch.float32)

                        # assemble query: [x, y, z, op_code, params...]
                        queries_op = torch.cat([xyz, op_value, sampled_params], dim=1)

                        # evaluate SDF
                        sdf_fn, _ = scene_with_operators[key]
                        sdf_op_vals = sdf_fn(xyz, sampled_params)
                        if sdf_op_vals.dim() == 1:
                            sdf_op_vals = sdf_op_vals.unsqueeze(1)

                        data = torch.cat([queries_op, sdf_op_vals], dim=1).numpy()
                        sdf_col_idx = data.shape[1] - 1
                        batch_pos = data[np.abs(data[:, sdf_col_idx]) < specs["ClampingDistance"]]
                        batch_neg = data[np.abs(data[:, sdf_col_idx]) >= specs["ClampingDistance"]]

                        if len(pos_list) < target_pos:
                            remaining = target_pos - len(pos_list)
                            pos_list.append(batch_pos[:remaining])
                        if len(neg_list) < target_neg:
                            remaining = target_neg - len(neg_list)
                            neg_list.append(batch_neg[:remaining])

                # ---------------- Combine all batches ----------------
                pos = np.vstack(pos_list) if pos_list else np.empty((0, batch_size), dtype=np.float32)
                neg = np.vstack(neg_list) if neg_list else np.empty((0, batch_size), dtype=np.float32)

                ## Determine if all scenes have exactly one operator
                all_scenes_single_operator = all(len(scene) == 1 for scene in self.scenes.values())

                # BEFORE saving - ensure we keep the sdf column (last column)
                if all_scenes_single_operator:
                    # pos/neg may have several forms:
                    # - [x,y,z,sdf]                 -> shape[1] == 4  (leave as-is)
                    # - [x,y,z,op_code,params...,sdf] -> shape[1] >= 5 (drop op_code at index 3)
                    # - if somehow other shapes appear, print shapes for debugging
                    if pos.size > 0:
                        if pos.shape[1] >= 5:
                            # drop only the op_code (index 3)
                            pos = np.concatenate([pos[:, :3], pos[:, 4:]], axis=1)
                        elif pos.shape[1] == 4:
                            # already [x,y,z,sdf] -> keep as-is
                            pass
                        else:
                            print(f"[WARN] Unexpected pos shape before saving: {pos.shape}")
                    if neg.size > 0:
                        if neg.shape[1] >= 5:
                            neg = np.concatenate([neg[:, :3], neg[:, 4:]], axis=1)
                        elif neg.shape[1] == 4:
                            pass
                        else:
                            print(f"[WARN] Unexpected neg shape before saving: {neg.shape}")

                # ---------------- Save ----------------
                np.savez_compressed(samples_file, pos=pos, neg=neg)

        # ---------------- Training Loop ----------------
        for scene_idx, (scene_id, scene_with_operators) in enumerate(self.scenes.items()):
            scene_key = f"{self.model_name.lower()}_{scene_id}"
            scene_folder = os.path.join(scenes_dir, scene_id)
            scene_latent_dir = os.path.join(scene_folder, "LatentCodes")
            os.makedirs(scene_latent_dir, exist_ok=True)


            # ---------------- Check per-scene latent snapshots ----------------
            existing_scene_ckpts = [
                f for f in os.listdir(scene_latent_dir) if f.endswith(".pth") and f[:-4].isdigit()
            ]
            if existing_scene_ckpts:
                continue
            
            # ---------------- Find latest latent checkpoint ----------------
            existing_model_ckpts = [
                f for f in os.listdir(model_params_dir)
                if f.endswith(".pth") and f[:-4].isdigit()
            ]
            existing_latent_ckpts = [
                f for f in os.listdir(top_latent_dir)
                if f.endswith(".pth") and f[:-4].isdigit()
            ]

            if existing_model_ckpts!= existing_latent_ckpts:
                print("[DEBUG] Mismatch between latent and model checkpoints")

            elif existing_model_ckpts:
                resume_ckpt = f"{latest_epoch}"
                print(f"[INFO] Resuming from epoch {latest_epoch}")
            else:
                resume_ckpt = None
                print("[INFO] Starting from scratch")


            # ---------------- Train ----------------
            if(latest_epoch < specs["NumEpochs"]):
                old_cwd = os.getcwd()
                os.chdir(self.base_directory)
                try:
                    logs_file = os.path.join(self.base_directory, "Logs.pth")
                    if os.path.exists(logs_file):
                        logs_data = torch.load(logs_file)
                        # update epoch to last checkpoint (or 0 if fresh)
                        logs_data["epoch"] = [latest_epoch]
                        torch.save(logs_data, logs_file)
                    else:
                        # Create minimal log if none exists
                        torch.save({
                            "loss": [0.0],
                            "learning_rate": [0.001],
                            "timing": [0.0],
                            "latent_magnitude": [0.0],
                            "param_magnitude": {"dummy": [0.0]},
                            "epoch": [latest_epoch],
                        }, logs_file)
                
                    training.train_deep_sdf(
                        experiment_directory=self.base_directory,
                        data_source=self.base_directory,
                        continue_from=resume_ckpt,
                        batch_split=1
                    )
                finally:
                    os.chdir(old_cwd)

            # ---------------- Load final top-level latent dict ----------------
            post_ckpts = [
                f for f in os.listdir(top_latent_dir)
                if f.endswith(".pth") and f[:-4].isdigit()
            ]
            if not post_ckpts:
                raise RuntimeError(f"No latent checkpoints found in {top_latent_dir}")

            final_epoch = max(int(f[:-4]) for f in post_ckpts)
            top_latent_path = os.path.join(top_latent_dir, f"{final_epoch}.pth")

            latent = torch.load(top_latent_path, map_location="cpu")
            if "latent_codes" not in latent or "weight" not in latent["latent_codes"]:
                raise ValueError(
                    f"Invalid latent checkpoint format at {top_latent_path}. "
                    f"Expected 'latent_codes[\"weight\"]'. Keys found: {latent.keys()}"
                )

            latent_weight = latent["latent_codes"]["weight"]

            # ---------------- Sanity check latent count ----------------
            expected_latents = scene_idx + 1
            if latent_weight.shape[0] > expected_latents:
                print(f"[WARN] Truncating latent matrix: {latent_weight.shape[0]} → {expected_latents}")
                latent_weight = latent_weight[:expected_latents]
            elif latent_weight.shape[0] < expected_latents:
                sigma = 1.0 / math.sqrt(self.latentDim)
                extra = torch.normal(0.0, sigma, size=(expected_latents - latent_weight.shape[0], self.latentDim))
                latent_weight = torch.cat([latent_weight, extra], dim=0)
                print(f"[INFO] Expanded latent matrix to {expected_latents} entries")

            # ---------------- Append latent for next scene (if any) ----------------
            if (scene_idx + 1) < len(self.scenes.keys()):
                sigma = 1.0 / math.sqrt(self.latentDim)
                new_latent = torch.normal(0.0, sigma, size=(1, self.latentDim))
                latent_weight = torch.cat([latent_weight, new_latent], dim=0)
                print(f"[INFO] Added latent vector for next scene index {scene_idx + 1}")

            # ---------------- Pad latent matrix to match TrainSplit (DeepSDF expectation) ----------------
            train_split_path = os.path.join(self.base_directory, "split", "TrainSplit.json")
            if os.path.exists(train_split_path):
                with open(train_split_path, "r") as f:
                    split = json.load(f)
                train_scene_count = len(split["train"].get(self.model_name, []))
                if train_scene_count > 0 and latent_weight.shape[0] != train_scene_count:
                    print(f"[WARN] Adjusting latent matrix to match TrainSplit: "
                        f"{latent_weight.shape[0]} → {train_scene_count}")
                    sigma = 1.0 / math.sqrt(self.latentDim)
                    if latent_weight.shape[0] < train_scene_count:
                        pad = torch.normal(0.0, sigma, size=(train_scene_count - latent_weight.shape[0], self.latentDim))
                        latent_weight = torch.cat([latent_weight, pad], dim=0)
                    else:
                        latent_weight = latent_weight[:train_scene_count]

            # ---------------- Update latent structure ----------------
            latent = {
                "latent_codes": {"weight": latent_weight},
                "epoch": 0 
            }


            # ---------------- Save per-scene latent ----------------
            scene_ckpt_file = os.path.join(scene_latent_dir, f"{final_epoch}.pth")
            torch.save(latent, scene_ckpt_file)
            print(f"[INFO] Saved per-scene latent for '{scene_id}' → {scene_ckpt_file}")

            # ---------------- Reset parameters ----------------
            optimizer_params_path = os.path.join(optimizer_params_dir, f"{final_epoch}.pth")
            optimizer_params = torch.load(optimizer_params_path,map_location="cpu" )
            new_optimizer_params_path = os.path.join(optimizer_params_dir, "0.pth")

            model_params_path = os.path.join(model_params_dir, f"{final_epoch}.pth")
            model_params = torch.load(model_params_path, map_location="cpu")
            new_model_params_ckpt_file = os.path.join(model_params_dir, "0.pth")

            # Reset any internal epoch counters if present
            if "epoch" in optimizer_params:
                optimizer_params["epoch"] = 0
            if "epoch" in model_params:
                model_params["epoch"] = 0

            # Clean directories for next run
            safe_clean_directory(top_latent_dir)
            safe_clean_directory(model_params_dir)
            safe_clean_directory(optimizer_params_dir)  

            torch.save (optimizer_params,new_optimizer_params_path )
            # Save reset model parameters
            torch.save(model_params, new_model_params_ckpt_file)
            print(f"[INFO] Reset model parameters saved to {new_model_params_ckpt_file}")

            # ---------------- Save updated top-level latent dict ----------------
            top_ckpt_file = os.path.join(top_latent_dir, "0.pth")
            torch.save(latent, top_ckpt_file)
            print(f"[INFO] Updated top-level latent dictionary saved to {top_ckpt_file}")

            # ---------------- Retrieve current scene latent ----------------
            latent_vector = latent_weight[scene_idx]
            self.trained_scenes[scene_key] = Scene(
                parent_model=self,
                scene_key=scene_key,
                latent_vector=latent_vector  # only this scene's vector
            )

    def get_scene(self, scene_key: str) -> "Scene":
        """Return a Scene instance by key."""
        return self.trained_scenes[scene_key]
    
class Scene():
    def __init__(self, parent_model: Model, scene_key: str, latent_vector: torch.Tensor):
        # Call the parent constructor to inherit model attributes
        self.parent_model = parent_model
        self.scene_key = scene_key
        self.latent_vector = latent_vector
        # Derive the raw scene id (everything after first underscore)
        raw_id = "_".join(scene_key.split("_")[1:])

        # Pull the operator dict from the parent model
        self.sdf_ops = self.parent_model.scenes.get(raw_id)
        if self.sdf_ops is None:
            raise KeyError(f"Scene id '{raw_id}' not found in parent model.scenes")

    def compute_sdf(self, xyz: torch.Tensor, params: torch.Tensor | None = None, operator: int = 0) -> torch.Tensor:
        """Compute SDF values for this scene using a given operator and optional parameters."""
            
        if self.sdf_ops is None:
            raise ValueError(f"No SDF operators defined for scene '{self.scene_key}'")

        # Lookup operator
        op_entry = self.sdf_ops.get(operator)
        if op_entry is None:
            raise KeyError(f"Operator index {operator} not found in scene '{self.scene_key}'")

        sdf_fn, _ = op_entry  # unpack (function, param_ranges)

        # Call the function with xyz and params
        try:
            sdf_vals = sdf_fn(xyz, params)
        except Exception as e:
            raise RuntimeError(f"Error evaluating SDF for scene '{self.scene_key}', operator {operator}: {e}")

        # Make sure output is the right shape
        if sdf_vals.dim() == 1:
            sdf_vals = sdf_vals.unsqueeze(1)

        return sdf_vals
            
        #(xyz, params)
        
    def get_latent_vector(self) -> torch.Tensor:
        """Return the latent vector for this scene."""
        return self.latent_vector
        
    def visualize(
        self,
        grid_res: int = 128,
        clamp_dist: float = 0.1,
        param_values: list | None = None,
        save_suffix: str | None = None,
        experiment_root: str | None = None,
        ):
        """
        Visualize this scene using the trained latent vector.

        Args:
            grid_res (int): Grid resolution.
            clamp_dist (float): Clamp distance for SDF values.
            param_values (list of list, optional): Parameter vectors to visualize.
            save_suffix (str, optional): Suffix for saved mesh files.
            experiment_root (str, optional): Root directory for experiments.

        Returns:
            List[trimesh.Trimesh]: Generated meshes.
        """
        # Extract scene_id from the scene_key assuming format: "modelname_###"
        scene_id_str = self.scene_key.split("_")[-1]
        scene_id = int(scene_id_str)

        return visualize_a_shape(
            model_name=self.parent_model.model_name,
            scene_id=scene_id,
            grid_res=grid_res,
            clamp_dist=clamp_dist,
            param_values=param_values,
            latent=self.latent_vector,
            save_suffix=save_suffix,
            experiment_root=experiment_root,
        )